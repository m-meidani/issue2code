{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import tensor\n",
    "from bpemb import BPEmb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from collections import Counter\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "\n",
    "import dask.dataframe as dd\n",
    "from dask.multiprocessing import get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpemb_en = BPEmb(lang=\"en\", dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_df = pd.read_pickle('issues_df.pkl', 'gzip')\n",
    "dataset_df = pd.read_pickle('dataset_df.pkl', 'gzip')\n",
    "dataset_df = dataset_df[dataset_df['tokenized'].map(lambda d: len(d)) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_df = pd.read_csv('./filtered_data/issues_data_etlegacy.csv')\n",
    "dataset_df = pd.read_csv('./filtered_data/file_data_etlegacy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = dataset_df.sample(frac=1).reset_index(drop=True)\n",
    "issues_df = issues_df.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>file_content</th>\n",
       "      <th>issue</th>\n",
       "      <th>related</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g_systemmsg.c</td>\n",
       "      <td>b'/*\\n * Wolfenstein: Enemy Territory GPL Sour...</td>\n",
       "      <td>332</td>\n",
       "      <td>False</td>\n",
       "      <td>[20, 9937, 9952, 9939, 0, 9917, 62, 5707, 19, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>be_interface.c</td>\n",
       "      <td>b'/*\\n * Wolfenstein: Enemy Territory GPL Sour...</td>\n",
       "      <td>244</td>\n",
       "      <td>False</td>\n",
       "      <td>[20, 9937, 9952, 9939, 0, 9917, 62, 5707, 19, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>snd_codec_ogg.c</td>\n",
       "      <td>/**\\n * Wolfenstein: Enemy Territory GPL Sourc...</td>\n",
       "      <td>610</td>\n",
       "      <td>True</td>\n",
       "      <td>[2781, 9939, 9939, 0, 62, 5707, 19, 3521, 9948...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g_missile.c</td>\n",
       "      <td>b'/*\\n * Wolfenstein: Enemy Territory GPL Sour...</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>[20, 9937, 9952, 9939, 0, 9917, 62, 5707, 19, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Omni-Bot.h</td>\n",
       "      <td>b'////////////////////////////////////////////...</td>\n",
       "      <td>1247</td>\n",
       "      <td>False</td>\n",
       "      <td>[20, 9937, 9952, 9952, 9952, 9952, 9952, 9952,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          filename                                       file_content  issue  \\\n",
       "0    g_systemmsg.c  b'/*\\n * Wolfenstein: Enemy Territory GPL Sour...    332   \n",
       "1   be_interface.c  b'/*\\n * Wolfenstein: Enemy Territory GPL Sour...    244   \n",
       "2  snd_codec_ogg.c  /**\\n * Wolfenstein: Enemy Territory GPL Sourc...    610   \n",
       "3      g_missile.c  b'/*\\n * Wolfenstein: Enemy Territory GPL Sour...      3   \n",
       "4       Omni-Bot.h  b'////////////////////////////////////////////...   1247   \n",
       "\n",
       "   related                                          tokenized  \n",
       "0    False  [20, 9937, 9952, 9939, 0, 9917, 62, 5707, 19, ...  \n",
       "1    False  [20, 9937, 9952, 9939, 0, 9917, 62, 5707, 19, ...  \n",
       "2     True  [2781, 9939, 9939, 0, 62, 5707, 19, 3521, 9948...  \n",
       "3    False  [20, 9937, 9952, 9939, 0, 9917, 62, 5707, 19, ...  \n",
       "4    False  [20, 9937, 9952, 9952, 9952, 9952, 9952, 9952,...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>make cURL optional Author: @JanSimek (Radegast...</td>\n",
       "      <td>[1166, 838, 9922, 2250, 853, 1305, 9948, 9912,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Replace Sys_OpenURL Author: @JanSimek (Radegas...</td>\n",
       "      <td>[3675, 378, 9920, 9976, 126, 19, 67, 9922, 130...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fix compatibility with Jaymod 2.2.0 Author: @J...</td>\n",
       "      <td>[4055, 9260, 2758, 97, 6763, 3154, 1672, 246, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Improve error message of sv_init.c SV_TouchCGa...</td>\n",
       "      <td>[5815, 7541, 6049, 27, 10, 9936, 9976, 6, 25, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Remove +button4 cmd Author: @IR4T4 (IR4T4)\\nDa...</td>\n",
       "      <td>[7709, 4489, 5274, 460, 9925, 6247, 9923, 1305...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "id                                                      \n",
       "1   make cURL optional Author: @JanSimek (Radegast...   \n",
       "12  Replace Sys_OpenURL Author: @JanSimek (Radegas...   \n",
       "9   Fix compatibility with Jaymod 2.2.0 Author: @J...   \n",
       "13  Improve error message of sv_init.c SV_TouchCGa...   \n",
       "6   Remove +button4 cmd Author: @IR4T4 (IR4T4)\\nDa...   \n",
       "\n",
       "                                            tokenized  \n",
       "id                                                     \n",
       "1   [1166, 838, 9922, 2250, 853, 1305, 9948, 9912,...  \n",
       "12  [3675, 378, 9920, 9976, 126, 19, 67, 9922, 130...  \n",
       "9   [4055, 9260, 2758, 97, 6763, 3154, 1672, 246, ...  \n",
       "13  [5815, 7541, 6049, 27, 10, 9936, 9976, 6, 25, ...  \n",
       "6   [7709, 4489, 5274, 460, 9925, 6247, 9923, 1305...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issues_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df['file_content'] = dataset_df['file_content'].fillna('')\n",
    "issues_df['title'] = issues_df['title'].fillna('')\n",
    "issues_df['body'] = issues_df['body'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_df['text'] = issues_df['title'] + ' ' + issues_df['body']\n",
    "issues_df = issues_df[['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize (text):\n",
    "    text = re.sub(r\"[^\\x00-\\x7F]+\", \" \", text)\n",
    "    regex = re.compile('[' + re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n]') # remove punctuation and numbers\n",
    "    nopunct = regex.sub(\" \", text.lower())\n",
    "    return bpemb_en.encode_ids(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_df['tokenized'] = issues_df.apply(lambda row: tokenize(row['text']), axis=1)\n",
    "ddata = dd.from_pandas(dataset_df, npartitions=30)\n",
    "dataset_df['tokenized'] = ddata.map_partitions(lambda df: df.apply(lambda row: tokenize(row['file_content']), axis=1)).compute(scheduler='processes')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "issues_df.apply(lambda x: vocab.update(str(x['title']).split()), axis=1)\n",
    "issues_df.apply(lambda x: vocab.update(str(x['body']).split()), axis=1)\n",
    "dataset_df.apply(lambda x: vocab.update(str(x['file_content']).split()), axis=1)\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SourceCodeDataset(Dataset):\n",
    "    def __init__(self, sourceCode, issues):\n",
    "        self.source_code = sourceCode\n",
    "        self.issues = issues\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.source_code)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        y = 1 if self.source_code.iloc[idx]['related'] == True else 0\n",
    "        y = tensor(y).float()\n",
    "        # Return shape : (code, issue, is_related)\n",
    "        return (tensor(self.source_code.iloc[idx]['tokenized']),\n",
    "                tensor(self.issues.loc[self.source_code.iloc[idx]['issue']]['tokenized'])), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SourceCodeDataset(dataset_df, issues_df)\n",
    "train_size = int(0.9 * len(dataset))\n",
    "valid_size = len(dataset) - train_size\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(dataset, [train_size, valid_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "# vocab_size = len(words)\n",
    "\n",
    "def pad_collate(batch):\n",
    "    (xx, yy) = zip(*batch)\n",
    "    (x1, x2) = zip(*xx)\n",
    "    \n",
    "    x1_lens = [len(x) for x in x1]\n",
    "    x2_lens = [len(x) for x in x2]\n",
    "    \n",
    "    x1_pad = pad_sequence(x1, batch_first=True, padding_value=0)\n",
    "    x2_pad = pad_sequence(x2, batch_first=True, padding_value=0)\n",
    "    \n",
    "    return x1_pad, x2_pad, tensor(yy), x1_lens, x2_lens, len(yy)\n",
    "\n",
    "train_dl = DataLoader(train_dataset, batch_size=batch_size, \n",
    "                      shuffle=True, collate_fn=pad_collate)\n",
    "\n",
    "val_dl = DataLoader(valid_dataset, batch_size=batch_size, collate_fn=pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class IssueLanguageModel(nn.Module):\n",
    "    def __init__(self, embedding_dim=300):\n",
    "        super(IssueLanguageModel, self).__init__()        \n",
    "        \n",
    "        self.embeddings = nn.Embedding.from_pretrained(tensor(bpemb_en.vectors))\n",
    "        \n",
    "        self.gru1 = nn.GRU(embedding_dim, 128, batch_first=True)\n",
    "        self.gru2 = nn.GRU(embedding_dim, 256, batch_first=True)\n",
    "        \n",
    "        self.linear = nn.Linear(384, 128)\n",
    "        self.linear2 = nn.Linear(128, 1)\n",
    "        \n",
    "        # Unfreeze embedding layer\n",
    "        # self.embeddings.weight.requires_grad=True\n",
    "    def forward(self, issue, source_code, issue_len, code_len):\n",
    "        issue_em = self.embeddings(issue)\n",
    "        code_em = self.embeddings(source_code)\n",
    "        \n",
    "        issue_packed = pack_padded_sequence(issue_em, issue_len, batch_first=True, enforce_sorted=False)\n",
    "        code_packed = pack_padded_sequence(code_em, code_len, batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "        output1, hidden1 = self.gru1(issue_packed)\n",
    "        output2, hidden2 = self.gru2(code_packed)\n",
    "        \n",
    "        \n",
    "        hidden = torch.cat((hidden1, hidden2), dim=2)\n",
    "        \n",
    "        out = self.linear(hidden[-1])\n",
    "        out = F.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IssueLanguageModel().to(device)\n",
    "loss_function = nn.BCEWithLogitsLoss(pos_weight=tensor(2))\n",
    "optimizer = optim.Adam(model.parameters(), 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    losses = []\n",
    "    for epoch in tqdm(range(epoch)):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        index = 0\n",
    "        for code, issue, labels, code_len, issue_len, y_len in tqdm(train_dl):\n",
    "            index += 1\n",
    "            code = code.long().to(device)\n",
    "            issue = issue.long().to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            log_probs = model(issue, code, issue_len, code_len)\n",
    "            \n",
    "            loss = loss_function(log_probs.view(-1), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            if index%20 == 0:\n",
    "                print(\"Loss at {}: {}\".format(index, loss.item()))\n",
    "            if index%50 == 0:\n",
    "                validation_metrics()\n",
    "        losses.append(total_loss)\n",
    "        print(\"Loss: {}\".format(sum(losses)/len(losses)))\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_metrics():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for code, issue, labels, code_len, issue_len, y_len in tqdm(val_dl):\n",
    "            code = code.long().to(device)\n",
    "            issue = issue.long().to(device)\n",
    "            labels = labels.to(device)\n",
    "            log_probs = model(issue, code, issue_len, code_len).view(-1)\n",
    "            loss = loss_function(log_probs, labels)\n",
    "            \n",
    "            pred = torch.sigmoid(log_probs)\n",
    "            correct += (pred==labels).sum()\n",
    "            total += labels.shape[0]\n",
    "            sum_loss += loss.item()*labels.shape[0]\n",
    "            break\n",
    "    return sum_loss/total, (correct/total).cpu().item() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3643073"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225.0"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function = nn.BCEWithLogitsLoss(pos_weight=tensor(3))\n",
    "input = tensor([900,-900,-900,900]).float()\n",
    "target = tensor([1,0,0,0]).float()\n",
    "loss_function(input, target).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b75bb7a7ac4d6e81e6617a8b26dcb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2225]) torch.Size([2, 2225, 300]) torch.Size([1, 2, 256])\n",
      "torch.Size([2, 13964]) torch.Size([2, 13964, 300]) torch.Size([1, 2, 256])\n",
      "torch.Size([2, 512])\n",
      "torch.Size([2, 1]) torch.Size([2])\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-289-fc5627fa9e61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-288-b8ee39a79fca>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/uWaterloo/CS680/Project/.venv/lib/python3.9/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/uWaterloo/CS680/Project/.venv/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "losses = train(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.title('Train BCE Losses')\n",
    "plt.ylabel('Binary Cross Entropy')\n",
    "plt.xlabel('Epoch #')\n",
    "plt.legend(['Train loss'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model(\"delete test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_df.to_pickle('issues_df.pkl', 'gzip', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df.to_pickle('dataset_df.pkl', 'gzip', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
